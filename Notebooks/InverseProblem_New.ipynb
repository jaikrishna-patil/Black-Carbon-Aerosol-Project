{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d55ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error,mean_squared_error\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96d9191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585923f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavelength</th>\n",
       "      <th>fractal_dimension</th>\n",
       "      <th>fraction_of_coating</th>\n",
       "      <th>primary_particle_size</th>\n",
       "      <th>number_of_primary_particles</th>\n",
       "      <th>vol_equi_radius_outer</th>\n",
       "      <th>vol_equi_radius_inner</th>\n",
       "      <th>equi_mobility_dia</th>\n",
       "      <th>mie_epsilon</th>\n",
       "      <th>length_scale_factor</th>\n",
       "      <th>...</th>\n",
       "      <th>q_sca</th>\n",
       "      <th>g</th>\n",
       "      <th>c_geo</th>\n",
       "      <th>c_ext</th>\n",
       "      <th>c_abs</th>\n",
       "      <th>c_sca</th>\n",
       "      <th>ssa</th>\n",
       "      <th>mac_total</th>\n",
       "      <th>mac_bc</th>\n",
       "      <th>mac_organics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>660</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.829600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>706.858347</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>2.750000e-07</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>3.897000</td>\n",
       "      <td>3.897000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.898816</td>\n",
       "      <td>18.898816</td>\n",
       "      <td>33.934547</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>1122.067684</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1.130000e-06</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>4.047873</td>\n",
       "      <td>4.047873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.811016</td>\n",
       "      <td>23.811016</td>\n",
       "      <td>48.324498</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>1781.171422</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>4.480000e-06</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>4.212336</td>\n",
       "      <td>4.212336</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>27.256809</td>\n",
       "      <td>27.256809</td>\n",
       "      <td>59.425643</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>2333.994837</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>9.770000e-06</td>\n",
       "      <td>0.017756</td>\n",
       "      <td>4.248847</td>\n",
       "      <td>4.248847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.816510</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.051049</td>\n",
       "      <td>2827.433388</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>1.690000e-05</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>4.291000</td>\n",
       "      <td>4.291000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wavelength  fractal_dimension  fraction_of_coating  primary_particle_size  \\\n",
       "0         660                1.5                    0                   15.0   \n",
       "1         660                1.5                    0                   15.0   \n",
       "2         660                1.5                    0                   15.0   \n",
       "3         660                1.5                    0                   15.0   \n",
       "4         660                1.5                    0                   15.0   \n",
       "\n",
       "   number_of_primary_particles  vol_equi_radius_outer  vol_equi_radius_inner  \\\n",
       "0                            1              15.000000              15.000000   \n",
       "1                            2              18.898816              18.898816   \n",
       "2                            4              23.811016              23.811016   \n",
       "3                            6              27.256809              27.256809   \n",
       "4                            8              30.000000              30.000000   \n",
       "\n",
       "   equi_mobility_dia  mie_epsilon  length_scale_factor  ...     q_sca  \\\n",
       "0          23.829600            2               0.0952  ...  0.000389   \n",
       "1          33.934547            2               0.0952  ...  0.001005   \n",
       "2          48.324498            2               0.0952  ...  0.002514   \n",
       "3          59.425643            2               0.0952  ...  0.004187   \n",
       "4          68.816510            2               0.0952  ...  0.005988   \n",
       "\n",
       "          g        c_geo     c_ext     c_abs         c_sca       ssa  \\\n",
       "0  0.003798   706.858347  0.000083  0.000083  2.750000e-07  0.003318   \n",
       "1  0.008979  1122.067684  0.000173  0.000172  1.130000e-06  0.006529   \n",
       "2  0.022970  1781.171422  0.000362  0.000357  4.480000e-06  0.012376   \n",
       "3  0.037044  2333.994837  0.000550  0.000541  9.770000e-06  0.017756   \n",
       "4  0.051049  2827.433388  0.000745  0.000728  1.690000e-05  0.022730   \n",
       "\n",
       "   mac_total    mac_bc  mac_organics  \n",
       "0   3.897000  3.897000           0.0  \n",
       "1   4.047873  4.047873           0.0  \n",
       "2   4.212336  4.212336           0.0  \n",
       "3   4.248847  4.248847           0.0  \n",
       "4   4.291000  4.291000           0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('database.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8aa998",
   "metadata": {},
   "source": [
    "# Using vol_equi_radius_outer as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee6cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfbbde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal_dimension</th>\n",
       "      <th>fraction_of_coating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fractal_dimension  fraction_of_coating\n",
       "0                1.5                    0\n",
       "1                1.5                    0\n",
       "2                1.5                    0\n",
       "3                1.5                    0\n",
       "4                1.5                    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,[0,6,24,25,26,27]]\n",
    "Y = df.iloc[:,[1,2]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=0.25, \n",
    "        random_state=42)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27855145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6490c83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=0.25, \n",
    "        random_state=42)\n",
    "Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c07f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_x=StandardScaler()\n",
    "X_train=scaling_x.fit_transform(X_train)\n",
    "X_test=scaling_x.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5807e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06853dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=Sequential()\n",
    "    input_layer= Input(shape= (X_train.shape[1],))\n",
    "    first_dense=Dense(units=256, kernel_initializer='normal', activation= 'relu')(input_layer)\n",
    "    second_dense=Dense(units=256, kernel_initializer='normal', activation= 'relu')(first_dense)\n",
    "    third_dense=Dense(units=224, kernel_initializer='normal', activation= 'relu')(second_dense)\n",
    "    fourth_dense=Dense(units=256, kernel_initializer='normal', activation= 'relu')(third_dense)\n",
    "    fifth_dense=Dense(units=224, kernel_initializer='normal', activation= 'relu')(fourth_dense)\n",
    "    sixth_dense=Dense(units=128, kernel_initializer='normal', activation= 'relu')(fifth_dense)\n",
    "    seventh_dense=Dense(units=64, kernel_initializer='normal', activation= 'relu')(sixth_dense)\n",
    "    eighth_dense=Dense(units=32, kernel_initializer='normal', activation= 'relu')(seventh_dense)\n",
    "    output_dense=Dense(units=2, kernel_initializer='normal', activation= 'relu')(eighth_dense)\n",
    "    #output_dense[:,0]=tf.keras.activations.sigmoid(output_dense[:,0])\n",
    "    #output_q_abs=  tf.keras.layers.Activation(tf.nn.softplus)(output_dense[:,0:1])\n",
    "    #output_q_sca= tf.keras.layers.Activation(tf.nn.softplus)(output_dense[:,1:2])\n",
    "    #output_g= tf.keras.layers.Activation(tf.nn.sigmoid)(output_dense[:,2:3])\n",
    "    #print(output_dense.shape)\n",
    "   \n",
    "    \n",
    "    #model=tf.keras.Model(inputs=input_layer, outputs= [output_q_abs, output_q_sca, output_g])\n",
    "    model=tf.keras.Model(inputs=input_layer, outputs= output_dense)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e5b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 224)               57568     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               57600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 224)               57568     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               28800     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 279,522\n",
      "Trainable params: 279,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= build_model()\n",
    "\n",
    "#optimizer= tf.keras.optimizers.Adam(lr= 0.001)\n",
    "# model.compile(optimizer='adam',\n",
    "#              loss={\n",
    "#                  'q_abs': 'mean_absolute_percentage_error',\n",
    "#                  'q_sca': 'mean_absolute_percentage_error',\n",
    "#                  'g': 'mean_absolute_percentage_error'\n",
    "#              },\n",
    "#              metrics={\n",
    "#                  'q_abs': 'mean_absolute_percentage_error',\n",
    "#                  'q_sca': 'mean_absolute_percentage_error',\n",
    "#                  'g': 'mean_absolute_percentage_error'\n",
    "#              })\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5d3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878b0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"inverse_random_split_with_min_max_2/best_model.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a43a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c50fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv=CSVLogger('inverse_random_split_loss_logs.csv', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57a7a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list=[checkpoint, es, log_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83b49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "185/185 [==============================] - 5s 9ms/step - loss: 69156.1484 - mean_absolute_percentage_error: 69156.1484 - val_loss: 48.1387 - val_mean_absolute_percentage_error: 48.1387\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 48.13869, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47.6651 - mean_absolute_percentage_error: 47.6651 - val_loss: 47.3582 - val_mean_absolute_percentage_error: 47.3582\n",
      "\n",
      "Epoch 00002: val_loss improved from 48.13869 to 47.35817, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 47.1831 - mean_absolute_percentage_error: 47.1831 - val_loss: 46.9444 - val_mean_absolute_percentage_error: 46.9444\n",
      "\n",
      "Epoch 00003: val_loss improved from 47.35817 to 46.94443, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.8597 - mean_absolute_percentage_error: 46.8597 - val_loss: 46.6703 - val_mean_absolute_percentage_error: 46.6703\n",
      "\n",
      "Epoch 00004: val_loss improved from 46.94443 to 46.67030, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.6534 - mean_absolute_percentage_error: 46.6534 - val_loss: 46.5050 - val_mean_absolute_percentage_error: 46.5050\n",
      "\n",
      "Epoch 00005: val_loss improved from 46.67030 to 46.50503, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.5269 - mean_absolute_percentage_error: 46.5269 - val_loss: 46.4341 - val_mean_absolute_percentage_error: 46.4341\n",
      "\n",
      "Epoch 00006: val_loss improved from 46.50503 to 46.43407, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.4377 - mean_absolute_percentage_error: 46.4377 - val_loss: 46.3345 - val_mean_absolute_percentage_error: 46.3345\n",
      "\n",
      "Epoch 00007: val_loss improved from 46.43407 to 46.33448, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 46.3778 - mean_absolute_percentage_error: 46.3778 - val_loss: 46.2617 - val_mean_absolute_percentage_error: 46.2617\n",
      "\n",
      "Epoch 00008: val_loss improved from 46.33448 to 46.26170, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.3043 - mean_absolute_percentage_error: 46.3043 - val_loss: 46.2178 - val_mean_absolute_percentage_error: 46.2178\n",
      "\n",
      "Epoch 00009: val_loss improved from 46.26170 to 46.21775, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.2546 - mean_absolute_percentage_error: 46.2546 - val_loss: 46.1343 - val_mean_absolute_percentage_error: 46.1343\n",
      "\n",
      "Epoch 00010: val_loss improved from 46.21775 to 46.13430, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.1922 - mean_absolute_percentage_error: 46.1922 - val_loss: 46.1096 - val_mean_absolute_percentage_error: 46.1096\n",
      "\n",
      "Epoch 00011: val_loss improved from 46.13430 to 46.10962, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 46.1341 - mean_absolute_percentage_error: 46.1341 - val_loss: 46.0206 - val_mean_absolute_percentage_error: 46.0206\n",
      "\n",
      "Epoch 00012: val_loss improved from 46.10962 to 46.02057, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.0728 - mean_absolute_percentage_error: 46.0728 - val_loss: 45.9681 - val_mean_absolute_percentage_error: 45.9681\n",
      "\n",
      "Epoch 00013: val_loss improved from 46.02057 to 45.96812, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 46.0176 - mean_absolute_percentage_error: 46.0176 - val_loss: 45.9030 - val_mean_absolute_percentage_error: 45.9030\n",
      "\n",
      "Epoch 00014: val_loss improved from 45.96812 to 45.90297, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.9467 - mean_absolute_percentage_error: 45.9467 - val_loss: 45.8427 - val_mean_absolute_percentage_error: 45.8427\n",
      "\n",
      "Epoch 00015: val_loss improved from 45.90297 to 45.84270, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45.8732 - mean_absolute_percentage_error: 45.8732 - val_loss: 45.8192 - val_mean_absolute_percentage_error: 45.8192\n",
      "\n",
      "Epoch 00016: val_loss improved from 45.84270 to 45.81918, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45.8183 - mean_absolute_percentage_error: 45.8183 - val_loss: 45.7292 - val_mean_absolute_percentage_error: 45.7292\n",
      "\n",
      "Epoch 00017: val_loss improved from 45.81918 to 45.72916, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45.7300 - mean_absolute_percentage_error: 45.7300 - val_loss: 45.7108 - val_mean_absolute_percentage_error: 45.7108\n",
      "\n",
      "Epoch 00018: val_loss improved from 45.72916 to 45.71077, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 45.6634 - mean_absolute_percentage_error: 45.6634 - val_loss: 45.5765 - val_mean_absolute_percentage_error: 45.5765\n",
      "\n",
      "Epoch 00019: val_loss improved from 45.71077 to 45.57653, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 45.5834 - mean_absolute_percentage_error: 45.5834 - val_loss: 45.5431 - val_mean_absolute_percentage_error: 45.5431\n",
      "\n",
      "Epoch 00020: val_loss improved from 45.57653 to 45.54312, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.5078 - mean_absolute_percentage_error: 45.5078 - val_loss: 45.4359 - val_mean_absolute_percentage_error: 45.4359\n",
      "\n",
      "Epoch 00021: val_loss improved from 45.54312 to 45.43590, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.4121 - mean_absolute_percentage_error: 45.4121 - val_loss: 45.3462 - val_mean_absolute_percentage_error: 45.3462\n",
      "\n",
      "Epoch 00022: val_loss improved from 45.43590 to 45.34624, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.3237 - mean_absolute_percentage_error: 45.3237 - val_loss: 45.2914 - val_mean_absolute_percentage_error: 45.2914\n",
      "\n",
      "Epoch 00023: val_loss improved from 45.34624 to 45.29136, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.2274 - mean_absolute_percentage_error: 45.2274 - val_loss: 45.1810 - val_mean_absolute_percentage_error: 45.1810\n",
      "\n",
      "Epoch 00024: val_loss improved from 45.29136 to 45.18099, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.1408 - mean_absolute_percentage_error: 45.1408 - val_loss: 45.0905 - val_mean_absolute_percentage_error: 45.0905\n",
      "\n",
      "Epoch 00025: val_loss improved from 45.18099 to 45.09049, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 45.0366 - mean_absolute_percentage_error: 45.0366 - val_loss: 44.9912 - val_mean_absolute_percentage_error: 44.9912\n",
      "\n",
      "Epoch 00026: val_loss improved from 45.09049 to 44.99115, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.9415 - mean_absolute_percentage_error: 44.9415 - val_loss: 44.8968 - val_mean_absolute_percentage_error: 44.8968\n",
      "\n",
      "Epoch 00027: val_loss improved from 44.99115 to 44.89685, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.8478 - mean_absolute_percentage_error: 44.8478 - val_loss: 44.8056 - val_mean_absolute_percentage_error: 44.8056\n",
      "\n",
      "Epoch 00028: val_loss improved from 44.89685 to 44.80564, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.7453 - mean_absolute_percentage_error: 44.7453 - val_loss: 44.7137 - val_mean_absolute_percentage_error: 44.7137\n",
      "\n",
      "Epoch 00029: val_loss improved from 44.80564 to 44.71367, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.6502 - mean_absolute_percentage_error: 44.6502 - val_loss: 44.6159 - val_mean_absolute_percentage_error: 44.6159\n",
      "\n",
      "Epoch 00030: val_loss improved from 44.71367 to 44.61594, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.5527 - mean_absolute_percentage_error: 44.5527 - val_loss: 44.5149 - val_mean_absolute_percentage_error: 44.5149\n",
      "\n",
      "Epoch 00031: val_loss improved from 44.61594 to 44.51490, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.4597 - mean_absolute_percentage_error: 44.4597 - val_loss: 44.4514 - val_mean_absolute_percentage_error: 44.4514\n",
      "\n",
      "Epoch 00032: val_loss improved from 44.51490 to 44.45137, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.3652 - mean_absolute_percentage_error: 44.3652 - val_loss: 44.3301 - val_mean_absolute_percentage_error: 44.3301\n",
      "\n",
      "Epoch 00033: val_loss improved from 44.45137 to 44.33014, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.2420 - mean_absolute_percentage_error: 44.2420 - val_loss: 44.2672 - val_mean_absolute_percentage_error: 44.2672\n",
      "\n",
      "Epoch 00034: val_loss improved from 44.33014 to 44.26723, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.1292 - mean_absolute_percentage_error: 44.1292 - val_loss: 44.1329 - val_mean_absolute_percentage_error: 44.1329\n",
      "\n",
      "Epoch 00035: val_loss improved from 44.26723 to 44.13285, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 44.0118 - mean_absolute_percentage_error: 44.0118 - val_loss: 44.0703 - val_mean_absolute_percentage_error: 44.0703\n",
      "\n",
      "Epoch 00036: val_loss improved from 44.13285 to 44.07034, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.9304 - mean_absolute_percentage_error: 43.9304 - val_loss: 44.0016 - val_mean_absolute_percentage_error: 44.0016\n",
      "\n",
      "Epoch 00037: val_loss improved from 44.07034 to 44.00161, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.8317 - mean_absolute_percentage_error: 43.8317 - val_loss: 43.8920 - val_mean_absolute_percentage_error: 43.8920\n",
      "\n",
      "Epoch 00038: val_loss improved from 44.00161 to 43.89197, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.7698 - mean_absolute_percentage_error: 43.7698 - val_loss: 43.7955 - val_mean_absolute_percentage_error: 43.7955\n",
      "\n",
      "Epoch 00039: val_loss improved from 43.89197 to 43.79552, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - ETA: 0s - loss: 43.5677 - mean_absolute_percentage_error: 43.56 - 1s 7ms/step - loss: 43.6580 - mean_absolute_percentage_error: 43.6580 - val_loss: 43.7385 - val_mean_absolute_percentage_error: 43.7385\n",
      "\n",
      "Epoch 00040: val_loss improved from 43.79552 to 43.73846, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.6241 - mean_absolute_percentage_error: 43.6241 - val_loss: 43.6524 - val_mean_absolute_percentage_error: 43.6524\n",
      "\n",
      "Epoch 00041: val_loss improved from 43.73846 to 43.65242, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.5399 - mean_absolute_percentage_error: 43.5399 - val_loss: 43.5802 - val_mean_absolute_percentage_error: 43.5802\n",
      "\n",
      "Epoch 00042: val_loss improved from 43.65242 to 43.58023, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.4536 - mean_absolute_percentage_error: 43.4536 - val_loss: 43.5627 - val_mean_absolute_percentage_error: 43.5627\n",
      "\n",
      "Epoch 00043: val_loss improved from 43.58023 to 43.56269, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.4332 - mean_absolute_percentage_error: 43.4332 - val_loss: 43.4247 - val_mean_absolute_percentage_error: 43.4247\n",
      "\n",
      "Epoch 00044: val_loss improved from 43.56269 to 43.42475, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43.3394 - mean_absolute_percentage_error: 43.3394 - val_loss: 43.3914 - val_mean_absolute_percentage_error: 43.3914\n",
      "\n",
      "Epoch 00045: val_loss improved from 43.42475 to 43.39135, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43.3455 - mean_absolute_percentage_error: 43.3455 - val_loss: 43.3236 - val_mean_absolute_percentage_error: 43.3236\n",
      "\n",
      "Epoch 00046: val_loss improved from 43.39135 to 43.32360, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43.1973 - mean_absolute_percentage_error: 43.1973 - val_loss: 43.2316 - val_mean_absolute_percentage_error: 43.2316\n",
      "\n",
      "Epoch 00047: val_loss improved from 43.32360 to 43.23158, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 43.1745 - mean_absolute_percentage_error: 43.1745 - val_loss: 43.1581 - val_mean_absolute_percentage_error: 43.1581\n",
      "\n",
      "Epoch 00048: val_loss improved from 43.23158 to 43.15808, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 43.1641 - mean_absolute_percentage_error: 43.1641 - val_loss: 43.2334 - val_mean_absolute_percentage_error: 43.2334\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 43.15808\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43.1193 - mean_absolute_percentage_error: 43.1193 - val_loss: 43.0150 - val_mean_absolute_percentage_error: 43.0150\n",
      "\n",
      "Epoch 00050: val_loss improved from 43.15808 to 43.01505, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 43.0830 - mean_absolute_percentage_error: 43.0830 - val_loss: 43.0731 - val_mean_absolute_percentage_error: 43.0731\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 43.01505\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.9668 - mean_absolute_percentage_error: 42.9668 - val_loss: 43.4209 - val_mean_absolute_percentage_error: 43.4209\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 43.01505\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.9393 - mean_absolute_percentage_error: 42.9393 - val_loss: 43.0408 - val_mean_absolute_percentage_error: 43.0408\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 43.01505\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.9184 - mean_absolute_percentage_error: 42.9184 - val_loss: 43.0067 - val_mean_absolute_percentage_error: 43.0067\n",
      "\n",
      "Epoch 00054: val_loss improved from 43.01505 to 43.00671, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.8172 - mean_absolute_percentage_error: 42.8172 - val_loss: 43.0201 - val_mean_absolute_percentage_error: 43.0201\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 43.00671\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.7900 - mean_absolute_percentage_error: 42.7900 - val_loss: 42.8385 - val_mean_absolute_percentage_error: 42.8385\n",
      "\n",
      "Epoch 00056: val_loss improved from 43.00671 to 42.83852, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.7442 - mean_absolute_percentage_error: 42.7442 - val_loss: 42.9383 - val_mean_absolute_percentage_error: 42.9383\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 42.83852\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.7595 - mean_absolute_percentage_error: 42.7595 - val_loss: 42.6816 - val_mean_absolute_percentage_error: 42.6816\n",
      "\n",
      "Epoch 00058: val_loss improved from 42.83852 to 42.68162, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.8182 - mean_absolute_percentage_error: 42.8182 - val_loss: 42.8279 - val_mean_absolute_percentage_error: 42.8279\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 42.68162\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.7638 - mean_absolute_percentage_error: 42.7638 - val_loss: 42.5558 - val_mean_absolute_percentage_error: 42.5558\n",
      "\n",
      "Epoch 00060: val_loss improved from 42.68162 to 42.55582, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.6542 - mean_absolute_percentage_error: 42.6542 - val_loss: 42.7812 - val_mean_absolute_percentage_error: 42.7812\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 42.55582\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.7168 - mean_absolute_percentage_error: 42.7168 - val_loss: 43.2020 - val_mean_absolute_percentage_error: 43.2020\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 42.55582\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.6194 - mean_absolute_percentage_error: 42.6194 - val_loss: 42.4457 - val_mean_absolute_percentage_error: 42.4457\n",
      "\n",
      "Epoch 00063: val_loss improved from 42.55582 to 42.44573, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.9346 - mean_absolute_percentage_error: 42.9346 - val_loss: 42.8762 - val_mean_absolute_percentage_error: 42.8762\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 42.44573\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.4921 - mean_absolute_percentage_error: 42.4921 - val_loss: 42.5880 - val_mean_absolute_percentage_error: 42.5880\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 42.44573\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.6041 - mean_absolute_percentage_error: 42.6041 - val_loss: 42.4087 - val_mean_absolute_percentage_error: 42.4087\n",
      "\n",
      "Epoch 00066: val_loss improved from 42.44573 to 42.40871, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.6464 - mean_absolute_percentage_error: 42.6464 - val_loss: 42.2024 - val_mean_absolute_percentage_error: 42.2024\n",
      "\n",
      "Epoch 00067: val_loss improved from 42.40871 to 42.20242, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.4740 - mean_absolute_percentage_error: 42.4740 - val_loss: 44.0536 - val_mean_absolute_percentage_error: 44.0536\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 42.20242\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.6360 - mean_absolute_percentage_error: 42.6360 - val_loss: 43.7246 - val_mean_absolute_percentage_error: 43.7246\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 42.20242\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.4862 - mean_absolute_percentage_error: 42.4862 - val_loss: 42.5943 - val_mean_absolute_percentage_error: 42.5943\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 42.20242\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.7368 - mean_absolute_percentage_error: 42.7368 - val_loss: 42.6140 - val_mean_absolute_percentage_error: 42.6140\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 42.20242\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.3830 - mean_absolute_percentage_error: 42.3830 - val_loss: 43.3341 - val_mean_absolute_percentage_error: 43.3341\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 42.20242\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.6052 - mean_absolute_percentage_error: 42.6052 - val_loss: 42.3755 - val_mean_absolute_percentage_error: 42.3755\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 42.20242\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.3321 - mean_absolute_percentage_error: 42.3321 - val_loss: 42.3950 - val_mean_absolute_percentage_error: 42.3950\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 42.20242\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.4959 - mean_absolute_percentage_error: 42.4959 - val_loss: 42.2200 - val_mean_absolute_percentage_error: 42.2200\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 42.20242\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.2428 - mean_absolute_percentage_error: 42.2428 - val_loss: 42.3259 - val_mean_absolute_percentage_error: 42.3259\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 42.20242\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.3895 - mean_absolute_percentage_error: 42.3895 - val_loss: 41.9818 - val_mean_absolute_percentage_error: 41.9818\n",
      "\n",
      "Epoch 00077: val_loss improved from 42.20242 to 41.98185, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.4506 - mean_absolute_percentage_error: 42.4506 - val_loss: 43.0126 - val_mean_absolute_percentage_error: 43.0126\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 41.98185\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.3700 - mean_absolute_percentage_error: 42.3700 - val_loss: 42.7150 - val_mean_absolute_percentage_error: 42.7150\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 41.98185\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.2024 - mean_absolute_percentage_error: 42.2024 - val_loss: 42.5813 - val_mean_absolute_percentage_error: 42.5813\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 41.98185\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.3390 - mean_absolute_percentage_error: 42.3390 - val_loss: 42.5845 - val_mean_absolute_percentage_error: 42.5845\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 41.98185\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.2142 - mean_absolute_percentage_error: 42.2142 - val_loss: 42.8716 - val_mean_absolute_percentage_error: 42.8716\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 41.98185\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.4725 - mean_absolute_percentage_error: 42.4725 - val_loss: 43.3661 - val_mean_absolute_percentage_error: 43.3661\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 41.98185\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 7ms/step - loss: 42.3389 - mean_absolute_percentage_error: 42.3389 - val_loss: 42.4822 - val_mean_absolute_percentage_error: 42.4822\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 41.98185\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.2487 - mean_absolute_percentage_error: 42.2487 - val_loss: 42.1535 - val_mean_absolute_percentage_error: 42.1535\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 41.98185\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1892 - mean_absolute_percentage_error: 42.1892 - val_loss: 42.5651 - val_mean_absolute_percentage_error: 42.5651\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 41.98185\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.2131 - mean_absolute_percentage_error: 42.2131 - val_loss: 42.0007 - val_mean_absolute_percentage_error: 42.0007\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 41.98185\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1472 - mean_absolute_percentage_error: 42.1472 - val_loss: 42.5060 - val_mean_absolute_percentage_error: 42.5060\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 41.98185\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1188 - mean_absolute_percentage_error: 42.1188 - val_loss: 41.9957 - val_mean_absolute_percentage_error: 41.9957\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 41.98185\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1859 - mean_absolute_percentage_error: 42.1859 - val_loss: 42.6510 - val_mean_absolute_percentage_error: 42.6510\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 41.98185\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.3214 - mean_absolute_percentage_error: 42.3214 - val_loss: 42.2806 - val_mean_absolute_percentage_error: 42.2806\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 41.98185\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 42.0490 - mean_absolute_percentage_error: 42.0490 - val_loss: 42.2526 - val_mean_absolute_percentage_error: 42.2526\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 41.98185\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1676 - mean_absolute_percentage_error: 42.1676 - val_loss: 43.0529 - val_mean_absolute_percentage_error: 43.0529\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 41.98185\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1261 - mean_absolute_percentage_error: 42.1261 - val_loss: 41.9797 - val_mean_absolute_percentage_error: 41.9797\n",
      "\n",
      "Epoch 00094: val_loss improved from 41.98185 to 41.97969, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.1137 - mean_absolute_percentage_error: 42.1137 - val_loss: 42.7898 - val_mean_absolute_percentage_error: 42.7898\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 41.97969\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1825 - mean_absolute_percentage_error: 42.1825 - val_loss: 42.6435 - val_mean_absolute_percentage_error: 42.6435\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 41.97969\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1006 - mean_absolute_percentage_error: 42.1006 - val_loss: 43.4267 - val_mean_absolute_percentage_error: 43.4267\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 41.97969\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0146 - mean_absolute_percentage_error: 42.0146 - val_loss: 43.3848 - val_mean_absolute_percentage_error: 43.3848\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 41.97969\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1771 - mean_absolute_percentage_error: 42.1771 - val_loss: 42.3622 - val_mean_absolute_percentage_error: 42.3622\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 41.97969\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1771 - mean_absolute_percentage_error: 42.1771 - val_loss: 42.5150 - val_mean_absolute_percentage_error: 42.5150\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 41.97969\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.2106 - mean_absolute_percentage_error: 42.2106 - val_loss: 42.1397 - val_mean_absolute_percentage_error: 42.1397\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 41.97969\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1110 - mean_absolute_percentage_error: 42.1110 - val_loss: 43.2531 - val_mean_absolute_percentage_error: 43.2531\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 41.97969\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1381 - mean_absolute_percentage_error: 42.1381 - val_loss: 42.4340 - val_mean_absolute_percentage_error: 42.4340\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 41.97969\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1859 - mean_absolute_percentage_error: 42.1859 - val_loss: 42.5706 - val_mean_absolute_percentage_error: 42.5706\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 41.97969\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1676 - mean_absolute_percentage_error: 42.1676 - val_loss: 42.0639 - val_mean_absolute_percentage_error: 42.0639\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 41.97969\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1741 - mean_absolute_percentage_error: 42.1741 - val_loss: 42.1163 - val_mean_absolute_percentage_error: 42.1163\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 41.97969\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0966 - mean_absolute_percentage_error: 42.0966 - val_loss: 42.3377 - val_mean_absolute_percentage_error: 42.3377\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 41.97969\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.3501 - mean_absolute_percentage_error: 42.3501 - val_loss: 42.3760 - val_mean_absolute_percentage_error: 42.3760\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 41.97969\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0838 - mean_absolute_percentage_error: 42.0838 - val_loss: 42.9271 - val_mean_absolute_percentage_error: 42.9271\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 41.97969\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1066 - mean_absolute_percentage_error: 42.1066 - val_loss: 42.5245 - val_mean_absolute_percentage_error: 42.5245\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 41.97969\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1521 - mean_absolute_percentage_error: 42.1521 - val_loss: 42.1987 - val_mean_absolute_percentage_error: 42.1987\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 41.97969\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0662 - mean_absolute_percentage_error: 42.0662 - val_loss: 42.6866 - val_mean_absolute_percentage_error: 42.6866\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 41.97969\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.3164 - mean_absolute_percentage_error: 42.3164 - val_loss: 42.2136 - val_mean_absolute_percentage_error: 42.2136\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 41.97969\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0826 - mean_absolute_percentage_error: 42.0826 - val_loss: 42.5630 - val_mean_absolute_percentage_error: 42.5630\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 41.97969\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.2201 - mean_absolute_percentage_error: 42.2201 - val_loss: 42.5966 - val_mean_absolute_percentage_error: 42.5966\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 41.97969\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 42.1203 - mean_absolute_percentage_error: 42.1203 - val_loss: 42.1581 - val_mean_absolute_percentage_error: 42.1581\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 41.97969\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.0565 - mean_absolute_percentage_error: 42.0565 - val_loss: 42.6359 - val_mean_absolute_percentage_error: 42.6359\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 41.97969\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.2600 - mean_absolute_percentage_error: 42.2600 - val_loss: 41.6323 - val_mean_absolute_percentage_error: 41.6323\n",
      "\n",
      "Epoch 00118: val_loss improved from 41.97969 to 41.63231, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0109 - mean_absolute_percentage_error: 42.0109 - val_loss: 42.8435 - val_mean_absolute_percentage_error: 42.8435\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 41.63231\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.2201 - mean_absolute_percentage_error: 42.2201 - val_loss: 42.7859 - val_mean_absolute_percentage_error: 42.7859\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 41.63231\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.3868 - mean_absolute_percentage_error: 42.3868 - val_loss: 42.6325 - val_mean_absolute_percentage_error: 42.6325\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 41.63231\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.3038 - mean_absolute_percentage_error: 42.3038 - val_loss: 42.2930 - val_mean_absolute_percentage_error: 42.2930\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 41.63231\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.2460 - mean_absolute_percentage_error: 42.2460 - val_loss: 42.2450 - val_mean_absolute_percentage_error: 42.2450\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 41.63231\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.0846 - mean_absolute_percentage_error: 42.0846 - val_loss: 41.9126 - val_mean_absolute_percentage_error: 41.9126\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 41.63231\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.0573 - mean_absolute_percentage_error: 42.0573 - val_loss: 41.8588 - val_mean_absolute_percentage_error: 41.8588\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 41.63231\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.2148 - mean_absolute_percentage_error: 42.2148 - val_loss: 42.0455 - val_mean_absolute_percentage_error: 42.0455\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 41.63231\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.0743 - mean_absolute_percentage_error: 42.0743 - val_loss: 42.7447 - val_mean_absolute_percentage_error: 42.7447\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 41.63231\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1765 - mean_absolute_percentage_error: 42.1765 - val_loss: 42.1084 - val_mean_absolute_percentage_error: 42.1084\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 41.63231\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1398 - mean_absolute_percentage_error: 42.1398 - val_loss: 42.2535 - val_mean_absolute_percentage_error: 42.2535\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 41.63231\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.0712 - mean_absolute_percentage_error: 42.0712 - val_loss: 42.4875 - val_mean_absolute_percentage_error: 42.4875\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 41.63231\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1700 - mean_absolute_percentage_error: 42.1700 - val_loss: 42.4719 - val_mean_absolute_percentage_error: 42.4719\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 41.63231\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.1913 - mean_absolute_percentage_error: 42.1913 - val_loss: 42.0509 - val_mean_absolute_percentage_error: 42.0509\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 41.63231\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0233 - mean_absolute_percentage_error: 42.0233 - val_loss: 42.0082 - val_mean_absolute_percentage_error: 42.0082\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 41.63231\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.1598 - mean_absolute_percentage_error: 42.1598 - val_loss: 42.2256 - val_mean_absolute_percentage_error: 42.2256\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 41.63231\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.2299 - mean_absolute_percentage_error: 42.2299 - val_loss: 41.9885 - val_mean_absolute_percentage_error: 41.9885\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 41.63231\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0557 - mean_absolute_percentage_error: 42.0557 - val_loss: 42.1829 - val_mean_absolute_percentage_error: 42.1829\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 41.63231\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0392 - mean_absolute_percentage_error: 42.0392 - val_loss: 42.4273 - val_mean_absolute_percentage_error: 42.4273\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 41.63231\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0528 - mean_absolute_percentage_error: 42.0528 - val_loss: 42.4348 - val_mean_absolute_percentage_error: 42.4348\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 41.63231\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 41.9162 - mean_absolute_percentage_error: 41.9162 - val_loss: 42.2355 - val_mean_absolute_percentage_error: 42.2355\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 41.63231\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 41.9476 - mean_absolute_percentage_error: 41.9476 - val_loss: 42.0656 - val_mean_absolute_percentage_error: 42.0656\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 41.63231\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 41.9562 - mean_absolute_percentage_error: 41.9562 - val_loss: 42.7797 - val_mean_absolute_percentage_error: 42.7797\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 41.63231\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 42.0929 - mean_absolute_percentage_error: 42.0929 - val_loss: 42.8369 - val_mean_absolute_percentage_error: 42.8369\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 41.63231\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 41.9355 - mean_absolute_percentage_error: 41.9355 - val_loss: 42.0673 - val_mean_absolute_percentage_error: 42.0673\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 41.63231\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 42.0290 - mean_absolute_percentage_error: 42.0290 - val_loss: 1675.5916 - val_mean_absolute_percentage_error: 1675.5916\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 41.63231\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 215372.8594 - mean_absolute_percentage_error: 215372.8594 - val_loss: 799.1821 - val_mean_absolute_percentage_error: 799.1821\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 41.63231\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 11430.6895 - mean_absolute_percentage_error: 11430.6895 - val_loss: 89.5575 - val_mean_absolute_percentage_error: 89.5575\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 41.63231\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4589 - mean_absolute_percentage_error: 89.4589 - val_loss: 89.5595 - val_mean_absolute_percentage_error: 89.5595\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 41.63231\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4565 - mean_absolute_percentage_error: 89.4565 - val_loss: 89.5592 - val_mean_absolute_percentage_error: 89.5592\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 41.63231\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.4546 - mean_absolute_percentage_error: 89.4546 - val_loss: 89.5598 - val_mean_absolute_percentage_error: 89.5598\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 41.63231\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 8ms/step - loss: 89.4519 - mean_absolute_percentage_error: 89.4519 - val_loss: 89.5597 - val_mean_absolute_percentage_error: 89.5597\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 41.63231\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4502 - mean_absolute_percentage_error: 89.4502 - val_loss: 89.5568 - val_mean_absolute_percentage_error: 89.5568\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 41.63231\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4470 - mean_absolute_percentage_error: 89.4470 - val_loss: 89.5534 - val_mean_absolute_percentage_error: 89.5534\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 41.63231\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4441 - mean_absolute_percentage_error: 89.4441 - val_loss: 89.5504 - val_mean_absolute_percentage_error: 89.5504\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 41.63231\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4423 - mean_absolute_percentage_error: 89.4423 - val_loss: 89.5471 - val_mean_absolute_percentage_error: 89.5471\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 41.63231\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4403 - mean_absolute_percentage_error: 89.4403 - val_loss: 89.5419 - val_mean_absolute_percentage_error: 89.5419\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 41.63231\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4341 - mean_absolute_percentage_error: 89.4341 - val_loss: 89.5402 - val_mean_absolute_percentage_error: 89.5402\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 41.63231\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4346 - mean_absolute_percentage_error: 89.4346 - val_loss: 89.5351 - val_mean_absolute_percentage_error: 89.5351\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 41.63231\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4338 - mean_absolute_percentage_error: 89.4338 - val_loss: 89.5276 - val_mean_absolute_percentage_error: 89.5276\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 41.63231\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.4222 - mean_absolute_percentage_error: 89.4222 - val_loss: 89.5220 - val_mean_absolute_percentage_error: 89.5220\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 41.63231\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.4224 - mean_absolute_percentage_error: 89.4224 - val_loss: 89.5109 - val_mean_absolute_percentage_error: 89.5109\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 41.63231\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 89.4077 - mean_absolute_percentage_error: 89.4077 - val_loss: 89.4913 - val_mean_absolute_percentage_error: 89.4913\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 41.63231\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.4005 - mean_absolute_percentage_error: 89.4005 - val_loss: 89.4540 - val_mean_absolute_percentage_error: 89.4540\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 41.63231\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.3534 - mean_absolute_percentage_error: 89.3534 - val_loss: 89.4081 - val_mean_absolute_percentage_error: 89.4081\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 41.63231\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.3092 - mean_absolute_percentage_error: 89.3092 - val_loss: 89.3990 - val_mean_absolute_percentage_error: 89.3990\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 41.63231\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.2853 - mean_absolute_percentage_error: 89.2853 - val_loss: 89.3767 - val_mean_absolute_percentage_error: 89.3767\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 41.63231\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.2598 - mean_absolute_percentage_error: 89.2598 - val_loss: 89.3663 - val_mean_absolute_percentage_error: 89.3663\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 41.63231\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.2337 - mean_absolute_percentage_error: 89.2337 - val_loss: 89.3507 - val_mean_absolute_percentage_error: 89.3507\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 41.63231\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.2095 - mean_absolute_percentage_error: 89.2095 - val_loss: 89.3365 - val_mean_absolute_percentage_error: 89.3365\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 41.63231\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.1624 - mean_absolute_percentage_error: 89.1624 - val_loss: 89.3193 - val_mean_absolute_percentage_error: 89.3193\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 41.63231\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.0911 - mean_absolute_percentage_error: 89.0911 - val_loss: 89.2214 - val_mean_absolute_percentage_error: 89.2214\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 41.63231\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88.7759 - mean_absolute_percentage_error: 88.7759 - val_loss: 89.0869 - val_mean_absolute_percentage_error: 89.0869\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 41.63231\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85.3949 - mean_absolute_percentage_error: 85.3949 - val_loss: 87.7397 - val_mean_absolute_percentage_error: 87.7397\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 41.63231\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85.6942 - mean_absolute_percentage_error: 85.6942 - val_loss: 87.7053 - val_mean_absolute_percentage_error: 87.7053\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 41.63231\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88.0571 - mean_absolute_percentage_error: 88.0571 - val_loss: 88.3126 - val_mean_absolute_percentage_error: 88.3126\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 41.63231\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 85.6408 - mean_absolute_percentage_error: 85.6408 - val_loss: 89.1515 - val_mean_absolute_percentage_error: 89.1515\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 41.63231\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.5300 - mean_absolute_percentage_error: 88.5300 - val_loss: 89.1741 - val_mean_absolute_percentage_error: 89.1741\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 41.63231\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.8719 - mean_absolute_percentage_error: 88.8719 - val_loss: 89.0294 - val_mean_absolute_percentage_error: 89.0294\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 41.63231\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 88.4161 - mean_absolute_percentage_error: 88.4161 - val_loss: 88.9020 - val_mean_absolute_percentage_error: 88.9020\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 41.63231\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.1755 - mean_absolute_percentage_error: 88.1755 - val_loss: 88.9977 - val_mean_absolute_percentage_error: 88.9977\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 41.63231\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 86.0918 - mean_absolute_percentage_error: 86.0918 - val_loss: 89.3001 - val_mean_absolute_percentage_error: 89.3001\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 41.63231\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - ETA: 0s - loss: 89.0286 - mean_absolute_percentage_error: 89.02 - 1s 7ms/step - loss: 89.0274 - mean_absolute_percentage_error: 89.0274 - val_loss: 89.1473 - val_mean_absolute_percentage_error: 89.1473\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 41.63231\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.8124 - mean_absolute_percentage_error: 88.8124 - val_loss: 88.0835 - val_mean_absolute_percentage_error: 88.0835\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 41.63231\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 88.6908 - mean_absolute_percentage_error: 88.6908 - val_loss: 89.0973 - val_mean_absolute_percentage_error: 89.0973\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 41.63231\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.8912 - mean_absolute_percentage_error: 88.8912 - val_loss: 89.3383 - val_mean_absolute_percentage_error: 89.3383\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 41.63231\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.0301 - mean_absolute_percentage_error: 89.0301 - val_loss: 89.1927 - val_mean_absolute_percentage_error: 89.1927\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 41.63231\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88.9363 - mean_absolute_percentage_error: 88.9363 - val_loss: 88.8861 - val_mean_absolute_percentage_error: 88.8861\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 41.63231\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.3973 - mean_absolute_percentage_error: 89.3973 - val_loss: 89.3660 - val_mean_absolute_percentage_error: 89.3660\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 41.63231\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88.9781 - mean_absolute_percentage_error: 88.9781 - val_loss: 88.9130 - val_mean_absolute_percentage_error: 88.9130\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 41.63231\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.7840 - mean_absolute_percentage_error: 88.7840 - val_loss: 89.2198 - val_mean_absolute_percentage_error: 89.2198\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 41.63231\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.9080 - mean_absolute_percentage_error: 88.9080 - val_loss: 89.0627 - val_mean_absolute_percentage_error: 89.0627\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 41.63231\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.8207 - mean_absolute_percentage_error: 88.8207 - val_loss: 89.3292 - val_mean_absolute_percentage_error: 89.3292\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 41.63231\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.0766 - mean_absolute_percentage_error: 89.0766 - val_loss: 89.1761 - val_mean_absolute_percentage_error: 89.1761\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 41.63231\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.9729 - mean_absolute_percentage_error: 88.9729 - val_loss: 88.9823 - val_mean_absolute_percentage_error: 88.9823\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 41.63231\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.7700 - mean_absolute_percentage_error: 88.7700 - val_loss: 88.7031 - val_mean_absolute_percentage_error: 88.7031\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 41.63231\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.9333 - mean_absolute_percentage_error: 88.9333 - val_loss: 88.5510 - val_mean_absolute_percentage_error: 88.5510\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 41.63231\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 88.3346 - mean_absolute_percentage_error: 88.3346 - val_loss: 89.0815 - val_mean_absolute_percentage_error: 89.0815\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 41.63231\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 89.1170 - mean_absolute_percentage_error: 89.1170 - val_loss: 89.6126 - val_mean_absolute_percentage_error: 89.6126\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 41.63231\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 89.4358 - mean_absolute_percentage_error: 89.4358 - val_loss: 89.3265 - val_mean_absolute_percentage_error: 89.3265\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 41.63231\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 88.7273 - mean_absolute_percentage_error: 88.7273 - val_loss: 89.4194 - val_mean_absolute_percentage_error: 89.4194\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 41.63231\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.1625 - mean_absolute_percentage_error: 89.1625 - val_loss: 89.7448 - val_mean_absolute_percentage_error: 89.7448\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 41.63231\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.5219 - mean_absolute_percentage_error: 89.5219 - val_loss: 89.5328 - val_mean_absolute_percentage_error: 89.5328\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 41.63231\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.3269 - mean_absolute_percentage_error: 89.3269 - val_loss: 89.4037 - val_mean_absolute_percentage_error: 89.4037\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 41.63231\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 89.1722 - mean_absolute_percentage_error: 89.1722 - val_loss: 89.1049 - val_mean_absolute_percentage_error: 89.1049\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 41.63231\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.0567 - mean_absolute_percentage_error: 89.0567 - val_loss: 88.7121 - val_mean_absolute_percentage_error: 88.7121\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 41.63231\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.9674 - mean_absolute_percentage_error: 88.9674 - val_loss: 89.3747 - val_mean_absolute_percentage_error: 89.3747\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 41.63231\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.1830 - mean_absolute_percentage_error: 89.1830 - val_loss: 89.3308 - val_mean_absolute_percentage_error: 89.3308\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 41.63231\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.0161 - mean_absolute_percentage_error: 89.0161 - val_loss: 89.1238 - val_mean_absolute_percentage_error: 89.1238\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 41.63231\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.8196 - mean_absolute_percentage_error: 88.8196 - val_loss: 85.4572 - val_mean_absolute_percentage_error: 85.4572\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 41.63231\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 88.8708 - mean_absolute_percentage_error: 88.8708 - val_loss: 89.8251 - val_mean_absolute_percentage_error: 89.8251\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 41.63231\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 2s 9ms/step - loss: 89.6676 - mean_absolute_percentage_error: 89.6676 - val_loss: 89.7715 - val_mean_absolute_percentage_error: 89.7715\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 41.63231\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 1s 8ms/step - loss: 89.5331 - mean_absolute_percentage_error: 89.5331 - val_loss: 89.4785 - val_mean_absolute_percentage_error: 89.4785\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 41.63231\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 89.3266 - mean_absolute_percentage_error: 89.3266 - val_loss: 89.6352 - val_mean_absolute_percentage_error: 89.6352\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 41.63231\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.3136 - mean_absolute_percentage_error: 89.3136 - val_loss: 89.2271 - val_mean_absolute_percentage_error: 89.2271\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 41.63231\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 2s 8ms/step - loss: 88.8765 - mean_absolute_percentage_error: 88.8765 - val_loss: 88.3340 - val_mean_absolute_percentage_error: 88.3340\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 41.63231\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 88.6860 - mean_absolute_percentage_error: 88.6860 - val_loss: 89.2407 - val_mean_absolute_percentage_error: 89.2407\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 41.63231\n",
      "Epoch 216/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 2s 8ms/step - loss: 89.1549 - mean_absolute_percentage_error: 89.1549 - val_loss: 88.9260 - val_mean_absolute_percentage_error: 88.9260\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 41.63231\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 89.0730 - mean_absolute_percentage_error: 89.0730 - val_loss: 88.8873 - val_mean_absolute_percentage_error: 88.8873\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 41.63231\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 2s 10ms/step - loss: 88.7684 - mean_absolute_percentage_error: 88.7684 - val_loss: 87.5606 - val_mean_absolute_percentage_error: 87.5606\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 41.63231\n",
      "Epoch 00218: early stopping\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callback_list)\n",
    "#history= NN_model.fit(X_train, Y_train, epochs=7, batch_size=32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1676b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest=tf.train.latest_checkpoint(checkpoint_dir)\n",
    "weights_file = 'inverse_random_split_with_min_max_2/best_model.hdf5' # choose the best checkpoint \n",
    "model.load_weights(weights_file) # load it\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa839a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('random_split_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50dab9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 41.552, Validation loss: 41.742\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdJElEQVR4nO3df5CU1Z3v8fd3eoZfioZfcrmADon4C9EBRnSLmLCFJWhyBX8QoSorrF7JD01pZZNbupUKXi3qmip3TVm1mNJIIK46oTQoSYku4rrmlkYZDKuAEjASGWEFARWvDDIz3/tHnx6emeluHoahH+B8XlVT3XP6eZ45/VTDp885zzmPuTsiIiKlVGVdARERObYpKEREpCwFhYiIlKWgEBGRshQUIiJSVnXWFehpgwcP9tra2qyrISJyXFmzZs1H7j6k2GsnXFDU1tbS2NiYdTVERI4rZvbXUq+p60lERMpSUIiISFkKChERKeuEG6MQkRPLgQMHaGpqorm5OeuqnBD69OnDiBEjqKmpSb2PgkJEjmlNTU3079+f2tpazCzr6hzX3J1du3bR1NTEqFGjUu+nricROaY1NzczaNAghUQPMDMGDRp02K0zBYWIHPMUEj2nO+dSQSEih+WZtR+wt/lA1tWQClJQiEhqOz5t5raGtaxY919ZV6ViPv74YxYuXHjY+1155ZV8/PHHPV+hDCgoRCS1L1rbAGhpjeeGZ6WCorW1tex+zz77LF/60peOUq0qS1c9iUhqhRtitkV0Z8w77riDd999l7q6Ompqajj55JMZNmwYa9euZcOGDcyYMYOtW7fS3NzMbbfdxrx584CDywl99tlnXHHFFXz1q1/llVdeYfjw4TzzzDP07ds343eWnoJCRFIrBERWt1D+379bz4Ztn/boMc/776cw/3+MKfn6vffey7p161i7di0vvfQS3/jGN1i3bl375aWLFi1i4MCB7Nu3j4suuohrr72WQYMGdTjGpk2beOKJJ3j44Yf51re+xVNPPcW3v/3tHn0fR5OCQkRSO9iiyLYeWZo4cWKHOQgPPPAAy5YtA2Dr1q1s2rSpS1CMGjWKuro6ACZMmMCWLVsqVd0eoaAQkdQKLYqsup7KffOvlJNOOqn9+UsvvcQLL7zAq6++Sr9+/Zg8eXLROQq9e/duf57L5di3b19F6tpTNJgtIqm1Rdii6N+/P3v37i362ieffMKAAQPo168f77zzDn/84x8rXLvKUItCRFLzjMcosjBo0CAmTZrE+eefT9++fRk6dGj7a9OmTeMXv/gFF1xwAWeffTaXXHJJhjU9ehQUIpJaoSURUU4A8Pjjjxct7927NytWrCj6WmEcYvDgwaxbt669/Ec/+lGP1+9oU9eTiKTmZDtGIdlQUIhIam1t4VE5EZVDBoWZjTSzfzezt81svZndFsoHmtlKM9sUHgck9rnTzDab2UYzm5oon2Bmb4XXHrCwOpWZ9Taz34Ty18ysNrHPnPA3NpnZnB599yJyWLK+6kmykaZF0QL8g7ufC1wC3GJm5wF3AKvcfTSwKvxOeG0WMAaYBiw0s1w41oPAPGB0+JkWym8C9rj7mcD9wM/CsQYC84GLgYnA/GQgiUhlefsYhYIiJocMCnff7u5vhOd7gbeB4cB0YEnYbAkwIzyfDjS4+353fw/YDEw0s2HAKe7+quc/Zb/utE/hWE8CU0JrYyqw0t13u/seYCUHw0VEKuxgiyLjikhFHdYYRegSGge8Bgx19+2QDxPgtLDZcGBrYremUDY8PO9c3mEfd28BPgEGlTlW53rNM7NGM2vcuXPn4bwlETkMhXxQ11NcUgeFmZ0MPAXc7u7lFlspdlcML1Pe3X0OFrg/5O717l4/ZMiQMlUTkSMRY4ti8uTJPP/88x3Kfv7zn/P973+/5PaNjY1A6aXG77rrLu67776yf/fpp59mw4YN7b//9Kc/5YUXXjjM2veMVEFhZjXkQ+Ixd/9tKP4wdCcRHneE8iZgZGL3EcC2UD6iSHmHfcysGjgV2F3mWCKSgRgn3M2ePZuGhoYOZQ0NDcyePfuQ+x7JUuOdg+Luu+/msssu69axjlSaq54MeAR4293/OfHScqBwFdIc4JlE+axwJdMo8oPWr4fuqb1mdkk45g2d9ikc6zrgxTCO8TxwuZkNCIPYl4cyEcnAwSU84gmK6667jt///vfs378fyE+k27ZtG48//jj19fWMGTOG+fPnF923traWjz76CIAFCxZw9tlnc9lll7Fx48b2bR5++GEuuugiLrzwQq699lo+//xzXnnlFZYvX86Pf/xj6urqePfdd5k7dy5PPvkkAKtWrWLcuHGMHTuWG2+8sb1utbW1zJ8/n/HjxzN27FjeeeedHjkHaWZmTwL+DnjLzNaGsn8E7gWWmtlNwPvATAB3X29mS4EN5K+YusXdC3f4+B6wGOgLrAg/kA+iR81sM/mWxKxwrN1mdg+wOmx3t7vv7t5bFZEj1daWcdfTijvgv97q2WP+t7Fwxb0lXx40aBATJ07kueeeY/r06TQ0NHD99ddz5513MnDgQFpbW5kyZQpvvvkmF1xwQdFjrFmzhoaGBv70pz/R0tLC+PHjmTBhAgDXXHMNN998MwA/+clPeOSRR/jBD37AVVddxTe/+U2uu+66Dsdqbm5m7ty5rFq1irPOOosbbriBBx98kNtvvx3IzwR/4403WLhwIffddx+//OUvj/gUpbnq6f+6u7n7Be5eF36edfdd7j7F3UeHx92JfRa4+1fc/Wx3X5Eob3T388Nrt4ZWA+7e7O4z3f1Md5/o7n9J7LMolJ/p7r864ncsIt0W6xIeye6nQrfT0qVLGT9+POPGjWP9+vUduok6+8Mf/sDVV19Nv379OOWUU7jqqqvaX1u3bh2XXnopY8eO5bHHHmP9+vVl67Jx40ZGjRrFWWedBcCcOXN4+eWX21+/5pprgJ5dzlxrPYlIaoUlPDIboyjzzf9omjFjBj/84Q9544032LdvHwMGDOC+++5j9erVDBgwgLlz5xZdXjwpzC/uYu7cuTz99NNceOGFLF68mJdeeqnscQ517gtLmudyOVpaWspum5aW8BCR1GK8FSrAySefzOTJk7nxxhuZPXs2n376KSeddBKnnnoqH374YcmFAQu+9rWvsWzZMvbt28fevXv53e9+1/7a3r17GTZsGAcOHOCxxx5rLy+1vPk555zDli1b2Lx5MwCPPvooX//613vonRanFoWIpBbj5bEFs2fP5pprrqGhoYFzzjmHcePGMWbMGL785S8zadKksvuOHz+e66+/nrq6Os444wwuvfTS9tfuueceLr74Ys444wzGjh3bHg6zZs3i5ptv5oEHHmgfxAbo06cPv/rVr5g5cyYtLS1cdNFFfPe73z06bzqwE+0yt/r6ei9cwywiPes//ryTOYte5+8n1VbsbnNvv/025557bkX+ViyKnVMzW+Pu9cW2V9eTiKTW1j6PIuOKSEUpKEQkvUjHKGKnoBCR1LJaZvxE6yLPUnfOpYJCRFI7ODO7cn+zT58+7Nq1S2HRA9ydXbt20adPn8PaT1c9iUhqbRms9TRixAiamprQytA9o0+fPowYMeLQGyYoKEQktUJAFG6JWgk1NTWMGjWqcn9QulDXk4ikFuuEu9gpKEQktSzGKCR7CgoRSa19jKLr/cPkBKagEJHUNOEuTgoKEUlNYxRxUlCISGoxLwoYMwWFiKSmFkWcFBQikloWE+4kewoKEUmtvUVRwQl3kj0FhYikltWigJItBYWIpKYJd3FSUIhIaoWJdhqjiIuCQkRSa9NVT1FSUIhIaq55FFFSUIhIam1thbWeJCYKChFJrdCS0BhFXBQUIpJaIR40RhEXBYWIpJbFHe4kewoKEUlNE+7ipKAQkdQOjlFkWw+pLAWFiKSmFkWcFBQikpqWGY+TgkJEUtOEuzgpKEQkNc2jiJOCQkRS061Q46SgEJHUtChgnBQUIpKat98KNeOKSEUdMijMbJGZ7TCzdYmyu8zsAzNbG36uTLx2p5ltNrONZjY1UT7BzN4Krz1gZhbKe5vZb0L5a2ZWm9hnjpltCj9zeuxdi0i36KqnOKVpUSwGphUpv9/d68LPswBmdh4wCxgT9lloZrmw/YPAPGB0+Ckc8yZgj7ufCdwP/CwcayAwH7gYmAjMN7MBh/0ORaTHtKlFEaVDBoW7vwzsTnm86UCDu+939/eAzcBEMxsGnOLur3q+7fprYEZinyXh+ZPAlNDamAqsdPfd7r4HWEnxwBKRCtEYRZyOZIziVjN7M3RNFb7pDwe2JrZpCmXDw/PO5R32cfcW4BNgUJljdWFm88ys0cwad+7ceQRvSUTKcc3MjlJ3g+JB4CtAHbAd+KdQbkW29TLl3d2nY6H7Q+5e7+71Q4YMKVNtETkS6nqKU7eCwt0/dPdWd28DHiY/hgD5b/0jE5uOALaF8hFFyjvsY2bVwKnku7pKHUtEMqLB7Dh1KyjCmEPB1UDhiqjlwKxwJdMo8oPWr7v7dmCvmV0Sxh9uAJ5J7FO4ouk64MUwjvE8cLmZDQhdW5eHMhHJyMEximzrIZVVfagNzOwJYDIw2MyayF+JNNnM6sh3BW0BvgPg7uvNbCmwAWgBbnH31nCo75G/gqovsCL8ADwCPGpmm8m3JGaFY+02s3uA1WG7u9097aC6iBwFWj02TocMCnefXaT4kTLbLwAWFClvBM4vUt4MzCxxrEXAokPVUUQqQxPu4qSZ2SKSmi6PjZOCQkRSU9dTnBQUIpJaIR6UE3FRUIhIarpxUZwUFCKSWltb/lE3LoqLgkJEUtMYRZwUFCKSmibcxUlBISKpOWpRxEhBISKpFfJBOREXBYWIpKYxijgpKEQkNc3MjpOCQkRSa9M8iigpKEQkvfYxCiVFTBQUIpKaWhRxUlCISGoHb4WqpIiJgkJEUtOEuzgpKEQktWRLQq2KeCgoRCS1ZEtCrYp4KChEJLVkK0JzKeKhoBCR1Dq2KBQUsVBQiEhqbR3GKDKsiFSUgkJEUnO1KKKkoBCR1No6jFFkWBGpKAWFiKSmFkWcFBQiklqHMYq2DCsiFaWgEJHU1KKIk4JCRFJr0zyKKCkoRCS1Dl1PGdZDKktBISKpJcNBLYp4KChEJLXkJbHKiXgoKEQkNa31FCcFhYikpgl3cVJQiEhqbW3J50qKWCgoRCQ1LQoYJwWFiHSLxijioaAQkdQ04S5OCgoRSU23Qo3TIYPCzBaZ2Q4zW5coG2hmK81sU3gckHjtTjPbbGYbzWxqonyCmb0VXnvAzCyU9zaz34Ty18ysNrHPnPA3NpnZnB571yLSLR3HKJQUsUjTolgMTOtUdgewyt1HA6vC75jZecAsYEzYZ6GZ5cI+DwLzgNHhp3DMm4A97n4mcD/ws3CsgcB84GJgIjA/GUgiUnnuUF1lgFoUMTlkULj7y8DuTsXTgSXh+RJgRqK8wd33u/t7wGZgopkNA05x91c9/zXk1532KRzrSWBKaG1MBVa6+2533wOspGtgiUgFuTu5EBSu1Z6i0d0xiqHuvh0gPJ4WyocDWxPbNYWy4eF55/IO+7h7C/AJMKjMsbows3lm1mhmjTt37uzmWxKRQ2lLtih0P4po9PRgthUp8zLl3d2nY6H7Q+5e7+71Q4YMSVVRETl8be5UtXc9qUURi+4GxYehO4nwuCOUNwEjE9uNALaF8hFFyjvsY2bVwKnku7pKHUtEMpIco1BOxKO7QbEcKFyFNAd4JlE+K1zJNIr8oPXroXtqr5ldEsYfbui0T+FY1wEvhnGM54HLzWxAGMS+PJSJSEba3MlVVbU/lzhUH2oDM3sCmAwMNrMm8lci3QssNbObgPeBmQDuvt7MlgIbgBbgFndvDYf6HvkrqPoCK8IPwCPAo2a2mXxLYlY41m4zuwdYHba72907D6qLSAV1vOpJQRGLQwaFu88u8dKUEtsvABYUKW8Ezi9S3kwImiKvLQIWHaqOIlIZbe7U5AotiowrIxWjmdkiklqbc/DyWLUooqGgEJHUkvMo1KKIh4JCRFJr6xAUSopYKChEJLU2DWZHSUEhIql1WMJDORENBYWIpKYJd3FSUIhIahqjiJOCQkRSS14eq6CIh4JCRFJr0xhFlBQUIpKaA9Va6yk6CgoRSU0T7uKkoBCR1DRGEScFhYik1uZOlWmtp9goKEQktY7LjGdcGakYBYWIpFJoQeRy6nqKjYJCRFIptCDUooiPgkJEUim0IHQ/ivgoKEQklUJQaK2n+CgoRCSVQjDo8tj4KChEJJXOXU8ao4iHgkJEUvH2wWwt4REbBUWwv6WV//jzTpr2fJ51VUSOSYVg0IS7+Cgogs+aW5iz6HVefGdH1lUROSa1Xx6bU9dTbBQUQXUufyq+aGnLuCYixybvMkahpIiFgiLoFYKiRV+TRIoq/NPImVoUsVFQBDWhOX1ALQqRojq3KDRGEQ8FRVD48B9oVVCIFNNlCQ81KaKhoAjMjF65Kg7owy9SVNdFAbOsjVSSgiKhJmfqehIpoeuigEqKWCgoEqpzVep6Eimh8zwKiYeCIqFGXU8iJRX+ZahFER8FRUIvdT2JlFQYvM7lCkt4ZFkbqSQFRYK6nkRK8y7zKJQUsVBQJNTkTF1PIiXofhTxUlAk1OSq1PUkUkKXZcb1pSoaCoqEGnU9iZTUvoSH7kcRHQVFQk3OtNaTSEnh8lhd9RSdIwoKM9tiZm+Z2VozawxlA81spZltCo8DEtvfaWabzWyjmU1NlE8Ix9lsZg+Y5UfLzKy3mf0mlL9mZrVHUt9Dqc5VafVYkRKSiwKaaa2nmPREi+Jv3b3O3evD73cAq9x9NLAq/I6ZnQfMAsYA04CFZpYL+zwIzANGh59pofwmYI+7nwncD/ysB+pbUi91PYmUdHDCXX7SnRrf8TgaXU/TgSXh+RJgRqK8wd33u/t7wGZgopkNA05x91c9/xXl1532KRzrSWBKobVxNKjrSaS0tvAdysyoMnU9xeRIg8KBfzOzNWY2L5QNdfftAOHxtFA+HNia2LcplA0PzzuXd9jH3VuAT4BBnSthZvPMrNHMGnfu3NntN6OuJ5HSki0KU4siKtVHuP8kd99mZqcBK83snTLbFmsJeJnycvt0LHB/CHgIoL6+vtsfX3U9iRxaoUWhMYp4HFGLwt23hccdwDJgIvBh6E4iPBZuQt0EjEzsPgLYFspHFCnvsI+ZVQOnAruPpM7lqOtJpLTOYxT6lxKPbgeFmZ1kZv0Lz4HLgXXAcmBO2GwO8Ex4vhyYFa5kGkV+0Pr10D2118wuCeMPN3Tap3Cs64AX/Sh+janWhDuRkgrfoarMMDThLiZH0vU0FFgWxpargcfd/TkzWw0sNbObgPeBmQDuvt7MlgIbgBbgFndvDcf6HrAY6AusCD8AjwCPmtlm8i2JWUdQ30OqyVXxRas+/CLFFFoUpqueotPtoHD3vwAXFinfBUwpsc8CYEGR8kbg/CLlzYSgqYReOaOlTS0KkWI8cT8K01VPUdHM7AR1PYmUlux6qqoyDWZHREGRkF/rSR9+kWIKuaCup/goKBJ65YwDbW36piRSRMcxCnU9xURBkVCdq8IdWvVVSaSLtg5jFGpRxERBkVATbvGo7ieRrjw5RqEJd1FRUCTU5PITwQ/oyieRLrouCqigiIWCIqG9RaErn0S60GB2vBQUCep6Eint4GC25lHERkGR0N71pIUBRbpIjlGYUWR5TjlRKSgSDrYoFBQinWmMIl4KigR1PYmU1mFmtsYooqKgSFDXk0hpnphwpzGKuCgoEtT1JFJaoQVh5FsUyol4KCgS1PUkUlr76rFVWsIjNgqKhELXU4taFCJddB2jUFDEQkGRUB1aFF8oKES6SF71pLWe4qKgSOgVgqJFXU8iXSQn3Gmtp7goKBJqqnXVk8ih6PLY+CgoEqqr1PUkUkp7iwINZsdGQZGgrieR0gqLKleFiRRqUcRDQZFQrQl3IiV1vsOdxijioaBI0IQ7kdLaFwWs0oS72CgoEnppwp1ISU5yUUCNUcREQZGgrieR0pJLeJgm3EVFQZGgrieR0jouM44GsyOioEg4uHqs/gWIdNbeorDCGIX+ncRCQZFgZlRXmVoUIkV4lxsXZVwhqRgFRSc1uSoFhUgRnW+FqjGKeCgoOqnJmbqeRIo4OEahJTxio6DoRC0KkeLag8Hy/072H2jNtD5SOQqKThQUIsUlxyiGf6kPH+zZpwHtSCgoOqmpNq31JFJEsutp5MB+7N3fwsefH8i4VlIJCopOaqqqtHqsSBHJO9ydMegkAN7f/XmGNZJKUVB0oq4nkeK8fR4FnD6wHwB/VVBEQUHRibqeRIpLdj0VgmKrgiIKCopOqtX1JFKUJ5YZ79srx5D+vfnrrv+Xca2kEhQUnfRS15NIUckxCoAzBvbTGEUkjougMLNpZrbRzDab2R1H82+p60mkuJoDnzLe/kxVWG789IH9eH+XgiIGx3xQmFkO+BfgCuA8YLaZnXe0/l51lVoUIl3s+5hr3/oOv+19F/av10DTGkYO7Mf2T5vZ36KJdyc6O9YnzJjZ3wB3ufvU8PudAO7+f4ptX19f742NjYf/hz7fDYumsv2TZj7/ooXq3DGfoSIV098/o7/vZUnLVP7nya9A88fs6zOUXftayVn+HhWSve39RjPuf63o1r5mtsbd64u9Vn1EtaqM4cDWxO9NwMXJDcxsHjAP4PTTT+/eX6mqhqFjqOq7n4/3qDktkvQR8MdTp3Fg1BS4dBi88ShVH/wnO7Z9SqsWfTpmtJx6xlE57vEQFMW+qnT4ZLr7Q8BDkG9RdOuv9DkFZi5mKDC0WwcQObFNSP7yN9+nNzA+o7pIZR0P/StNwMjE7yOAbRnVRUQkOsdDUKwGRpvZKDPrBcwClmdcJxGRaBzzXU/u3mJmtwLPAzlgkbuvz7haIiLROOaDAsDdnwWezboeIiIxOh66nkREJEMKChERKUtBISIiZSkoRESkrGN+CY/DZWY7gb8ewSEGk5+IKh3pvBSn81Kczktxx/J5OcPdhxR74YQLiiNlZo2l1juJmc5LcTovxem8FHe8nhd1PYmISFkKChERKUtB0dVDWVfgGKXzUpzOS3E6L8Udl+dFYxQiIlKWWhQiIlKWgkJERMpSUARmNs3MNprZZjO7I+v6ZMnMtpjZW2a21swaQ9lAM1tpZpvC44Cs63m0mdkiM9thZusSZSXPg5ndGT4/G81saja1rowS5+YuM/sgfG7WmtmViddO+HNjZiPN7N/N7G0zW29mt4Xy4/4zo6AAzCwH/AtwBXAeMNvMzsu2Vpn7W3evS1zzfQewyt1HA6vC7ye6xcC0TmVFz0P4vMwCxoR9FobP1YlqMV3PDcD94XNTF1Z9junctAD/4O7nApcAt4T3ftx/ZhQUeROBze7+F3f/AmgApmdcp2PNdGBJeL4EmJFdVSrD3V8GdncqLnUepgMN7r7f3d8DNpP/XJ2QSpybUqI4N+6+3d3fCM/3Am8DwzkBPjMKirzhwNbE702hLFYO/JuZrTGzeaFsqLtvh/w/COC0zGqXrVLnQZ+hvFvN7M3QNVXoYonu3JhZLTAOeI0T4DOjoMizImUxXzc8yd3Hk++Ku8XMvpZ1hY4D+gzBg8BXgDpgO/BPoTyqc2NmJwNPAbe7+6flNi1SdkyeFwVFXhMwMvH7CGBbRnXJnLtvC487gGXkm8MfmtkwgPC4I7saZqrUeYj+M+TuH7p7q7u3AQ9zsBslmnNjZjXkQ+Ixd/9tKD7uPzMKirzVwGgzG2VmvcgPMC3PuE6ZMLOTzKx/4TlwObCO/PmYEzabAzyTTQ0zV+o8LAdmmVlvMxsFjAZez6B+mSn8ZxhcTf5zA5GcGzMz4BHgbXf/58RLx/1n5ri4Z/bR5u4tZnYr8DyQAxa5+/qMq5WVocCy/GeeauBxd3/OzFYDS83sJuB9YGaGdawIM3sCmAwMNrMmYD5wL0XOg7uvN7OlwAbyV7/c4u6tmVS8Akqcm8lmVke++2QL8B2I6txMAv4OeMvM1oayf+QE+MxoCQ8RESlLXU8iIlKWgkJERMpSUIiISFkKChERKUtBISIiZSkoRESkLAWFiIiU9f8BR1Pw5OjV580AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train loss: %.3f, Validation loss: %.3f' % (train_loss, test_loss))\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a897d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fee2c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "#Y_pred[0]= pd.DataFrame(Y_pred[0], columns =['q_abs'])\n",
    "#Y_pred[1]= pd.DataFrame(Y_pred[1], columns =['q_sca'])\n",
    "#Y_pred[2]= pd.DataFrame(Y_pred[2], columns =['g'])\n",
    "#predictions= pd.concat([Y_pred[0], Y_pred[1], Y_pred[2]], axis=1)\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ebb378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error on test set:  [ 3.59037019 79.89417989]\n"
     ]
    }
   ],
   "source": [
    "error= mean_absolute_percentage_error(Y_test, Y_pred, multioutput='raw_values')   \n",
    "error=error*100\n",
    "print('Mean absolute percentage error on test set: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf77987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3671b80f",
   "metadata": {},
   "source": [
    "# Using vol_equi_radius_outer and primary_particle_size as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397daf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal_dimension</th>\n",
       "      <th>fraction_of_coating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fractal_dimension  fraction_of_coating\n",
       "0                1.5                    0\n",
       "1                1.5                    0\n",
       "2                1.5                    0\n",
       "3                1.5                    0\n",
       "4                1.5                    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,[0,3,6,24,25,26,27]]\n",
    "Y = df.iloc[:,[1,2]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=0.25, \n",
    "        random_state=42)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58714c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a585d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=0.25, \n",
    "        random_state=42)\n",
    "Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61280b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_x=StandardScaler()\n",
    "scaling_y=StandardScaler()\n",
    "X_train=scaling_x.fit_transform(X_train)\n",
    "X_test=scaling_x.transform(X_test)\n",
    "Y_train=scaling_y.fit_transform(Y_train)\n",
    "Y_test=scaling_y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ca4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515d52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=Sequential()\n",
    "    input_layer= Input(shape= (X_train.shape[1],))\n",
    "    first_dense=Dense(units=256, kernel_initializer='normal', activation= 'relu')(input_layer)\n",
    "    second_dense=Dense(units=256, kernel_initializer='normal', activation= 'relu')(first_dense)\n",
    "    third_dense=Dense(units=224, kernel_initializer='normal', activation= 'relu')(second_dense)\n",
    "    fourth_dense=Dense(units=256, kernel_initializer='normal', activation= 'relu')(third_dense)\n",
    "    fifth_dense=Dense(units=224, kernel_initializer='normal', activation= 'relu')(fourth_dense)\n",
    "    sixth_dense=Dense(units=128, kernel_initializer='normal', activation= 'relu')(fifth_dense)\n",
    "    seventh_dense=Dense(units=64, kernel_initializer='normal', activation= 'relu')(sixth_dense)\n",
    "    eighth_dense=Dense(units=32, kernel_initializer='normal', activation= 'relu')(seventh_dense)\n",
    "    output_dense=Dense(units=2, kernel_initializer='normal', activation= 'linear')(eighth_dense)\n",
    "    #output_dense[:,0]=tf.keras.activations.sigmoid(output_dense[:,0])\n",
    "    #output_q_abs=  tf.keras.layers.Activation(tf.nn.softplus)(output_dense[:,0:1])\n",
    "    #output_q_sca= tf.keras.layers.Activation(tf.nn.softplus)(output_dense[:,1:2])\n",
    "    #output_g= tf.keras.layers.Activation(tf.nn.sigmoid)(output_dense[:,2:3])\n",
    "    #print(output_dense.shape)\n",
    "   \n",
    "    \n",
    "    #model=tf.keras.Model(inputs=input_layer, outputs= [output_q_abs, output_q_sca, output_g])\n",
    "    model=tf.keras.Model(inputs=input_layer, outputs= output_dense)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71652ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 224)               57568     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               57600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 224)               57568     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               28800     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 279,778\n",
      "Trainable params: 279,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= build_model()\n",
    "\n",
    "#optimizer= tf.keras.optimizers.Adam(lr= 0.001)\n",
    "# model.compile(optimizer='adam',\n",
    "#              loss={\n",
    "#                  'q_abs': 'mean_absolute_percentage_error',\n",
    "#                  'q_sca': 'mean_absolute_percentage_error',\n",
    "#                  'g': 'mean_absolute_percentage_error'\n",
    "#              },\n",
    "#              metrics={\n",
    "#                  'q_abs': 'mean_absolute_percentage_error',\n",
    "#                  'q_sca': 'mean_absolute_percentage_error',\n",
    "#                  'g': 'mean_absolute_percentage_error'\n",
    "#              })\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e701a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54664773",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"inverse_random_split_with_min_max_2/best_model.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb9ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "299e872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv=CSVLogger('inverse_random_split_loss_logs.csv', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63383c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list=[checkpoint, es, log_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e04201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 4s 7ms/step - loss: 0.5172 - mean_absolute_error: 0.5172 - val_loss: 0.4343 - val_mean_absolute_error: 0.4343\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43426, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.3499 - mean_absolute_error: 0.3499 - val_loss: 0.2537 - val_mean_absolute_error: 0.2537\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43426 to 0.25370, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.2327 - mean_absolute_error: 0.2327 - val_loss: 0.2414 - val_mean_absolute_error: 0.2414\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25370 to 0.24139, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1970 - mean_absolute_error: 0.1970 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.24139 to 0.18461, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1663 - mean_absolute_error: 0.1663 - val_loss: 0.1800 - val_mean_absolute_error: 0.1800\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18461 to 0.17999, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1664 - mean_absolute_error: 0.1664 - val_loss: 0.1435 - val_mean_absolute_error: 0.1435\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17999 to 0.14347, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14347\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1403 - mean_absolute_error: 0.1403 - val_loss: 0.1509 - val_mean_absolute_error: 0.1509\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14347\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.1638 - val_mean_absolute_error: 0.1638\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14347\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.1708 - val_mean_absolute_error: 0.1708\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14347\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_split = 0.2, callbacks=callback_list)\n",
    "#history= NN_model.fit(X_train, Y_train, epochs=7, batch_size=32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1676b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest=tf.train.latest_checkpoint(checkpoint_dir)\n",
    "weights_file = 'inverse_random_split_with_min_max_2/best_model.hdf5' # choose the best checkpoint \n",
    "model.load_weights(weights_file) # load it\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa839a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('random_split_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50dab9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 100.908, Validation loss: 123.351\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train loss: %.3f, Validation loss: %.3f' % (train_loss, test_loss))\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a897d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f425f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fee2c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=scaling_y.inverse_transform(Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred=scaling_y.inverse_transform(Y_pred)\n",
    "\n",
    "#Y_pred[0]= pd.DataFrame(Y_pred[0], columns =['q_abs'])\n",
    "#Y_pred[1]= pd.DataFrame(Y_pred[1], columns =['q_sca'])\n",
    "#Y_pred[2]= pd.DataFrame(Y_pred[2], columns =['g'])\n",
    "#predictions= pd.concat([Y_pred[0], Y_pred[1], Y_pred[2]], axis=1)\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15238bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal_dimension</th>\n",
       "      <th>fraction_of_coating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.7</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>1.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>2.2</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>1.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fractal_dimension  fraction_of_coating\n",
       "0                   1.9                  0.0\n",
       "1                   2.2                 80.0\n",
       "2                   1.8                  5.0\n",
       "3                   1.7                 25.0\n",
       "4                   1.8                 25.0\n",
       "...                 ...                  ...\n",
       "2452                1.6                  5.0\n",
       "2453                2.2                 90.0\n",
       "2454                1.6                  5.0\n",
       "2455                2.0                 25.0\n",
       "2456                2.3                  0.0\n",
       "\n",
       "[2457 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = pd.DataFrame(data=Y_test, columns=[\"fractal_dimension\", \"fraction_of_coating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a025d39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8789816, -3.7007425],\n",
       "       [ 2.1715426, 78.101204 ],\n",
       "       [ 1.706214 ,  5.542677 ],\n",
       "       ...,\n",
       "       [ 1.554981 ,  1.9043103],\n",
       "       [ 1.9967672, 23.03694  ],\n",
       "       [ 2.2442477, -3.329065 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48ebb378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error on test set:  [0.05851313 1.23322157]\n"
     ]
    }
   ],
   "source": [
    "error= mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')   \n",
    "#error=error*100\n",
    "print('Mean absolute  error on test set: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb088b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb69f96",
   "metadata": {},
   "source": [
    "# Using vol_equi_radius_outer, primary_particle_size and fractal dimension as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfbbde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraction_of_coating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraction_of_coating\n",
       "0                    0\n",
       "1                    0\n",
       "2                    0\n",
       "3                    0\n",
       "4                    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,[0,1,3,6,7,8,9,10,11,12,13,24,25,26,27]]\n",
    "Y = df.iloc[:,[2]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=0.25, \n",
    "        random_state=42)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27855145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6490c83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=0.25, \n",
    "        random_state=42)\n",
    "Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c07f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_x=StandardScaler()\n",
    "X_train=scaling_x.fit_transform(X_train)\n",
    "X_test=scaling_x.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5807e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06853dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=Sequential()\n",
    "    input_layer= Input(shape= (X_train.shape[1],))\n",
    "    first_dense=Dense(units=512, kernel_initializer='he_normal', activation= 'relu')(input_layer)\n",
    "    second_dense=Dense(units=512, kernel_initializer='he_normal', activation= 'relu')(first_dense)\n",
    "    third_dense=Dense(units=484, kernel_initializer='he_normal', activation= 'relu')(second_dense)\n",
    "    fourth_dense=Dense(units=364, kernel_initializer='he_normal', activation= 'relu')(third_dense)\n",
    "    fifth_dense=Dense(units=484, kernel_initializer='he_normal', activation= 'relu')(fourth_dense)\n",
    "    sixth_dense=Dense(units=484, kernel_initializer='he_normal', activation= 'relu')(fifth_dense)\n",
    "    seventh_dense=Dense(units=128, kernel_initializer='he_normal', activation= 'relu')(sixth_dense)\n",
    "    eighth_dense=Dense(units=128, kernel_initializer='he_normal', activation= 'relu')(seventh_dense)\n",
    "    output_dense=Dense(units=1, kernel_initializer='he_normal', activation= 'linear')(eighth_dense)\n",
    "    #output_dense[:,0]=tf.keras.activations.sigmoid(output_dense[:,0])\n",
    "    #output_q_abs=  tf.keras.layers.Activation(tf.nn.softplus)(output_dense[:,0:1])\n",
    "    #output_q_sca= tf.keras.layers.Activation(tf.nn.softplus)(output_dense[:,1:2])\n",
    "    #output_g= tf.keras.layers.Activation(tf.nn.sigmoid)(output_dense[:,2:3])\n",
    "    #print(output_dense.shape)\n",
    "   \n",
    "    \n",
    "    #model=tf.keras.Model(inputs=input_layer, outputs= [output_q_abs, output_q_sca, output_g])\n",
    "    model=tf.keras.Model(inputs=input_layer, outputs= output_dense)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3e5b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               8192      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 484)               248292    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 364)               176540    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 484)               176660    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 484)               234740    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               62080     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,185,801\n",
      "Trainable params: 1,185,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= build_model()\n",
    "\n",
    "#optimizer= tf.keras.optimizers.Adam(lr= 0.001)\n",
    "# model.compile(optimizer='adam',\n",
    "#              loss={\n",
    "#                  'q_abs': 'mean_absolute_percentage_error',\n",
    "#                  'q_sca': 'mean_absolute_percentage_error',\n",
    "#                  'g': 'mean_absolute_percentage_error'\n",
    "#              },\n",
    "#              metrics={\n",
    "#                  'q_abs': 'mean_absolute_percentage_error',\n",
    "#                  'q_sca': 'mean_absolute_percentage_error',\n",
    "#                  'g': 'mean_absolute_percentage_error'\n",
    "#              })\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef5d3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "878b0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"inverse_random_split_with_min_max_2/best_model.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36a43a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4c50fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv=CSVLogger('inverse_random_split_loss_logs.csv', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57a7a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list=[checkpoint, es, log_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e83b49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 6s 18ms/step - loss: 28901524.0000 - mean_absolute_percentage_error: 28901524.0000 - val_loss: 1695759.5000 - val_mean_absolute_percentage_error: 1695759.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1695759.50000, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 3s 17ms/step - loss: 1283641.8750 - mean_absolute_percentage_error: 1283641.8750 - val_loss: 895338.0000 - val_mean_absolute_percentage_error: 895338.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1695759.50000 to 895338.00000, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 449806.2500 - mean_absolute_percentage_error: 449806.2500 - val_loss: 335347.6875 - val_mean_absolute_percentage_error: 335347.6875\n",
      "\n",
      "Epoch 00003: val_loss improved from 895338.00000 to 335347.68750, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 215965.9844 - mean_absolute_percentage_error: 215965.9844 - val_loss: 655304.8750 - val_mean_absolute_percentage_error: 655304.8750\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 335347.68750\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 3s 16ms/step - loss: 279511.4688 - mean_absolute_percentage_error: 279511.4688 - val_loss: 171656.1562 - val_mean_absolute_percentage_error: 171656.1562\n",
      "\n",
      "Epoch 00005: val_loss improved from 335347.68750 to 171656.15625, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 216504.7969 - mean_absolute_percentage_error: 216504.7969 - val_loss: 92744.6641 - val_mean_absolute_percentage_error: 92744.6641\n",
      "\n",
      "Epoch 00006: val_loss improved from 171656.15625 to 92744.66406, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 237804.0000 - mean_absolute_percentage_error: 237804.0000 - val_loss: 126777.9453 - val_mean_absolute_percentage_error: 126777.9453\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 92744.66406\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 342438.3750 - mean_absolute_percentage_error: 342438.3750 - val_loss: 241449.8750 - val_mean_absolute_percentage_error: 241449.8750\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 92744.66406\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 186268.7500 - mean_absolute_percentage_error: 186268.7500 - val_loss: 83636.0469 - val_mean_absolute_percentage_error: 83636.0469\n",
      "\n",
      "Epoch 00009: val_loss improved from 92744.66406 to 83636.04688, saving model to inverse_random_split_with_min_max_2\\best_model.hdf5\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 3s 15ms/step - loss: 155975.5469 - mean_absolute_percentage_error: 155975.5469 - val_loss: 286986.4688 - val_mean_absolute_percentage_error: 286986.4688\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 83636.04688\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_split = 0.2, callbacks=callback_list)\n",
    "#history= NN_model.fit(X_train, Y_train, epochs=7, batch_size=32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1676b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest=tf.train.latest_checkpoint(checkpoint_dir)\n",
    "weights_file = 'inverse_random_split_with_min_max_2/best_model.hdf5' # choose the best checkpoint \n",
    "model.load_weights(weights_file) # load it\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa839a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('random_split_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50dab9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 81841.359, Validation loss: 80376.477\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train loss: %.3f, Validation loss: %.3f' % (train_loss, test_loss))\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a897d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fee2c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "#Y_pred[0]= pd.DataFrame(Y_pred[0], columns =['q_abs'])\n",
    "#Y_pred[1]= pd.DataFrame(Y_pred[1], columns =['q_sca'])\n",
    "#Y_pred[2]= pd.DataFrame(Y_pred[2], columns =['g'])\n",
    "#predictions= pd.concat([Y_pred[0], Y_pred[1], Y_pred[2]], axis=1)\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48ebb378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error on test set:  [299.1627744]\n"
     ]
    }
   ],
   "source": [
    "error= mean_squared_error(Y_test, Y_pred, multioutput='raw_values')   \n",
    "#error=error*100\n",
    "print('Mean absolute percentage error on test set: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ffabfe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "autodetected range of [-inf, -inf] is not finite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12480/238220413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mhistplot\u001b[1;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munivariate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m         p.plot_univariate_histogram(\n\u001b[0m\u001b[0;32m   1463\u001b[0m             \u001b[0mmultiple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m             \u001b[0melement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mplot_univariate_histogram\u001b[1;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcommon_bins\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[0mall_observations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_variable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                 estimator.define_bin_params(\n\u001b[0m\u001b[0;32m    405\u001b[0m                     \u001b[0mall_observations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\seaborn\\_statistics.py\u001b[0m in \u001b[0;36mdefine_bin_params\u001b[1;34m(self, x1, x2, weights, cache)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             bin_edges = self._define_bin_edges(\n\u001b[0m\u001b[0;32m    270\u001b[0m                 \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscrete\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\seaborn\\_statistics.py\u001b[0m in \u001b[0;36m_define_bin_edges\u001b[1;34m(self, x, weights, bins, binwidth, binrange, discrete)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mbin_edges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             bin_edges = np.histogram_bin_edges(\n\u001b[0m\u001b[0;32m    261\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             )\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram_bin_edges\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36mhistogram_bin_edges\u001b[1;34m(a, bins, range, weights)\u001b[0m\n\u001b[0;32m    667\u001b[0m     \"\"\"\n\u001b[0;32m    668\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m     \u001b[0mbin_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[1;34m(a, bins, range, weights)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             \"bins is not supported for weighted data\")\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;31m# truncate the range if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TUK\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[1;34m(a, range)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    324\u001b[0m                 \"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: autodetected range of [-inf, -inf] is not finite"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAL2UlEQVR4nO3cT4xd91mH8eeLTSQI0KJmQMV/kJFMgxcNtBeXBYigCLCDhMWfRZKKiihiZKlGLBs2sOiKBRKKmsYaihW6qYVKBC4y9Q6yaCN5LJU0bpRo5Ip46qI4DapEu4icvixmKDe3d+aeGd/xjN88H2kkn3N+c847GuvR0bHvSVUhSbr7/dBuDyBJmg+DLklNGHRJasKgS1ITBl2SmjDoktTEzKAnOZfk9SQvbXA8SZ5KspLkxSQfmv+YkqRZhtyhPwuc2OT4SeDo+tci8MztjyVJ2qqZQa+q54E3N1lyCvhsrXkBeG+S989rQEnSMPN4hn4AuD62vbq+T5J0B+2fwzkyZd/U9wkkWWTtsQz33nvvh++///45XF6S3j2uXLnyRlUtTDs2j6CvAofGtg8CN6YtrKolYAlgNBrV8vLyHC4vSe8eSf5zo2PzeORyAfjY+v92+RXg21X1zTmcV5K0BTPv0JN8DngQuC/JKvCXwA8DVNVZ4CLwMLACfBd4fKeGlSRtbGbQq+rRGccL+PjcJpIkbYufFJWkJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJQUFPciLJK0lWkjw55fh7knwhyX8kuZrk8fmPKknazMygJ9kHPA2cBI4BjyY5NrHs48DXquoB4EHgr5PcM+dZJUmbGHKHfhxYqaprVfUWcB44NbGmgB9PEuDHgDeBW3OdVJK0qSFBPwBcH9teXd837lPALwA3gK8Cf1ZV35s8UZLFJMtJlm/evLnNkSVJ0wwJeqbsq4nt3wa+AvwM8IvAp5L8xA98U9VSVY2qarSwsLDFUSVJmxkS9FXg0Nj2QdbuxMc9DjxXa1aArwP3z2dESdIQQ4J+GTia5Mj6P3Q+AlyYWPMa8BBAkp8GPgBcm+egkqTN7Z+1oKpuJTkDXAL2Aeeq6mqS0+vHzwKfBJ5N8lXWHtF8oqre2MG5JUkTZgYdoKouAhcn9p0d+/MN4LfmO5okaSv8pKgkNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqYlBQU9yIskrSVaSPLnBmgeTfCXJ1ST/Pt8xJUmz7J+1IMk+4GngN4FV4HKSC1X1tbE17wU+DZyoqteS/NQOzStJ2sCQO/TjwEpVXauqt4DzwKmJNY8Bz1XVawBV9fp8x5QkzTIk6AeA62Pbq+v7xv088JNJ/i3JlSQfm9eAkqRhZj5yATJlX005z4eBh4AfAb6c5IWqevUdJ0oWgUWAw4cPb31aSdKGhtyhrwKHxrYPAjemrPliVX2nqt4AngcemDxRVS1V1aiqRgsLC9udWZI0xZCgXwaOJjmS5B7gEeDCxJp/Bn4tyf4kPwp8BHh5vqNKkjYz85FLVd1Kcga4BOwDzlXV1SSn14+fraqXk3wReBH4HvCZqnppJweXJL1TqiYfh98Zo9GolpeXd+XaknS3SnKlqkbTjvlJUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpoYFPQkJ5K8kmQlyZObrPvlJG8n+cP5jShJGmJm0JPsA54GTgLHgEeTHNtg3V8Bl+Y9pCRptiF36MeBlaq6VlVvAeeBU1PW/Snwj8Drc5xPkjTQkKAfAK6Pba+u7/u+JAeA3wPObnaiJItJlpMs37x5c6uzSpI2MSTombKvJrb/BvhEVb292YmqaqmqRlU1WlhYGDiiJGmI/QPWrAKHxrYPAjcm1oyA80kA7gMeTnKrqv5pHkNKkmYbEvTLwNEkR4BvAI8Aj40vqKoj//fnJM8C/2LMJenOmhn0qrqV5Axr/3tlH3Cuqq4mOb1+fNPn5pKkO2PIHTpVdRG4OLFvasir6o9vfyxJ0lb5SVFJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhODgp7kRJJXkqwkeXLK8Y8meXH960tJHpj/qJKkzcwMepJ9wNPASeAY8GiSYxPLvg78elV9EPgksDTvQSVJmxtyh34cWKmqa1X1FnAeODW+oKq+VFX/vb75AnBwvmNKkmYZEvQDwPWx7dX1fRt5AvjX2xlKkrR1+wesyZR9NXVh8husBf1XNzi+CCwCHD58eOCIkqQhhtyhrwKHxrYPAjcmFyX5IPAZ4FRVfWvaiapqqapGVTVaWFjYzrySpA0MCfpl4GiSI0nuAR4BLowvSHIYeA74o6p6df5jSpJmmfnIpapuJTkDXAL2Aeeq6mqS0+vHzwJ/AbwP+HQSgFtVNdq5sSVJk1I19XH4jhuNRrW8vLwr15aku1WSKxvdMPtJUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpoYFPQkJ5K8kmQlyZNTjifJU+vHX0zyofmPKknazMygJ9kHPA2cBI4BjyY5NrHsJHB0/WsReGbOc0qSZhhyh34cWKmqa1X1FnAeODWx5hTw2VrzAvDeJO+f86ySpE3sH7DmAHB9bHsV+MiANQeAb44vSrLI2h08wP8k+S/g21sZeN19wBvb+D5tz3vY3u9pr9urP9duzLXT19yJ88/jnLd7ju1+/+007Gc3OjAk6Jmyr7axhqpaApa+/03JUlUtTq6bOVCyXFWjrX6ftme7v6e9bq/+XLsx105fcyfOP49z3u459lrDhjxyWQUOjW0fBG5sY800XxiwRruv6+9pr/5cuzHXTl9zJ84/j3Pe7jn21N+hVP3AjfQ7FyT7gVeBh4BvAJeBx6rq6tia3wHOAA+z9jjmqao6vmNDe4cu6S62Uw2b+cilqm4lOQNcAvYB56rqapLT68fPAhdZi/kK8F3g8XkPOmFp9hJJ2rN2pGEz79AlSXcHPykqSU0YdElqwqBLUhMtgp7k3iR/n+Rvk3x0t+eRpKGS/FySv0vy+ds9154NepJzSV5P8tLE/mkvCvt94PNV9SfA797xYSVpzFb6tf5alSfmcd09G3TgWeDE+I5NXhR2kP9/9cDbd3BGSZrmWYb3a272bNCr6nngzYndG70obJW1qMMe/pkkvTtssV9zc7fFb6OXgD0H/EGSZ9hjH8WVpHVT+5XkfUnOAr+U5M9v5wJDXs61l0x9CVhVfYed/3SqJN2Ojfr1LeD0PC5wt92hb/clYJK023a8X3db0C8DR5McSXIP8AhwYZdnkqQhdrxfezboST4HfBn4QJLVJE9U1S3W3up4CXgZ+Ifxtz5K0l6wW/3y5VyS1MSevUOXJG2NQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1MT/AkoN2A9v8fsmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.histplot(Y_pred, log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65952e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2457, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1eadf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00059280626"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1383feff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00038915"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q_sca'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab103ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
